{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-01T15:58:48.098385Z","iopub.execute_input":"2022-06-01T15:58:48.099043Z","iopub.status.idle":"2022-06-01T15:58:59.284668Z","shell.execute_reply.started":"2022-06-01T15:58:48.098929Z","shell.execute_reply":"2022-06-01T15:58:59.283706Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import gc, os, cv2, PIL, torch\nimport torchvision as tv\nimport torch.nn as nn\nimport torchsummary as ts\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nfrom imblearn.over_sampling import RandomOverSampler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"execution":{"iopub.status.busy":"2022-06-01T15:58:59.286607Z","iopub.execute_input":"2022-06-01T15:58:59.289312Z","iopub.status.idle":"2022-06-01T15:59:04.033902Z","shell.execute_reply.started":"2022-06-01T15:58:59.289281Z","shell.execute_reply":"2022-06-01T15:59:04.033075Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"labels_df = pd.read_csv('../input/traffic-signs-classification/labels.csv')\nlabels_df","metadata":{"execution":{"iopub.status.busy":"2022-06-01T15:59:04.035311Z","iopub.execute_input":"2022-06-01T15:59:04.035773Z","iopub.status.idle":"2022-06-01T15:59:04.069591Z","shell.execute_reply.started":"2022-06-01T15:59:04.035728Z","shell.execute_reply":"2022-06-01T15:59:04.068625Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"%%time \n# %%time used to calculate total time taken to execute the cell\nx , y = [] , []  # X to store images and y to store respective labels  \ndata_dir = '../input/traffic-signs-classification/myData'\nfor folder in range(43):\n    folder_path = os.path.join(data_dir,str(folder)) # os.path.join just join both string \n    for i,img in enumerate(os.listdir(folder_path)):\n        img_path = os.path.join(folder_path,img)\n        # PIL load the image as PIL object and ToTensor() convert this to a Tensor\n        img_tensor = tv.transforms.ToTensor()(PIL.Image.open(img_path))\n        x.append(img_tensor.tolist()) # convert the tensor to list of list and append\n        y.append(folder)\n    print('folder of label',folder,'images loaded. Number of samples :',i+1)\nx = np.array(x)\ny = np.array(y)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T15:59:04.071674Z","iopub.execute_input":"2022-06-01T15:59:04.072150Z","iopub.status.idle":"2022-06-01T16:07:40.168255Z","shell.execute_reply.started":"2022-06-01T15:59:04.072112Z","shell.execute_reply":"2022-06-01T16:07:40.167316Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# np.unique returns all the labels as one array and \n#number of samples available respect to that label as another array.\nnp.unique(y,return_counts=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:07:40.169450Z","iopub.execute_input":"2022-06-01T16:07:40.169885Z","iopub.status.idle":"2022-06-01T16:07:40.179767Z","shell.execute_reply.started":"2022-06-01T16:07:40.169849Z","shell.execute_reply":"2022-06-01T16:07:40.178875Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"x = x.reshape(x.shape[0],3*32*32) # flatten x as RandomOverSampler only accepts 2-D matrix\n# RandomOverSampler method duplicates samples in the minority class to balance dataset\nx,y = RandomOverSampler().fit_resample(x,y)\nx = x.reshape(x.shape[0],3,32,32) # reshaped again as it was\nx.shape, y.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:07:40.181642Z","iopub.execute_input":"2022-06-01T16:07:40.182361Z","iopub.status.idle":"2022-06-01T16:07:47.647435Z","shell.execute_reply.started":"2022-06-01T16:07:40.182322Z","shell.execute_reply":"2022-06-01T16:07:47.646517Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"np.unique(y,return_counts=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:07:47.648904Z","iopub.execute_input":"2022-06-01T16:07:47.649425Z","iopub.status.idle":"2022-06-01T16:07:47.661121Z","shell.execute_reply.started":"2022-06-01T16:07:47.649387Z","shell.execute_reply":"2022-06-01T16:07:47.660065Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Stratified split on the dataset \nxtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,stratify=y)\ndel x,y\ngc.collect() # delete x,y and free the memory \nxtrain.shape, xtest.shape, ytrain.shape, ytest.shape # splited data shapes","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:07:47.663042Z","iopub.execute_input":"2022-06-01T16:07:47.663552Z","iopub.status.idle":"2022-06-01T16:07:49.484486Z","shell.execute_reply.started":"2022-06-01T16:07:47.663514Z","shell.execute_reply":"2022-06-01T16:07:49.483653Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(20,20)) \n# make_grid creates a grid of 100 images and show it\nplt.imshow(tv.utils.make_grid(torch.tensor(xtrain[:100]),nrow=10).permute(1,2,0))\nplt.axis('off') # To remove xticks and yticks\nplt.show()\nprint('\\n\\nLabels of the above images :\\n')\nytrain[:100]","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:07:49.485654Z","iopub.execute_input":"2022-06-01T16:07:49.486102Z","iopub.status.idle":"2022-06-01T16:07:49.857302Z","shell.execute_reply.started":"2022-06-01T16:07:49.486064Z","shell.execute_reply":"2022-06-01T16:07:49.856546Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"xtrain = torch.from_numpy(xtrain) \nytrain = torch.from_numpy(ytrain)\nxtest = torch.from_numpy(xtest)\nytest = torch.from_numpy(ytest)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:07:49.859771Z","iopub.execute_input":"2022-06-01T16:07:49.860519Z","iopub.status.idle":"2022-06-01T16:07:49.865419Z","shell.execute_reply.started":"2022-06-01T16:07:49.860480Z","shell.execute_reply":"2022-06-01T16:07:49.864754Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"\n\nmodel = nn.Sequential(\n                        # 1st convolutional network Layers\n                        nn.Conv2d(3,16,(2,2),(1,1),'same'),   # Convolution\n                        nn.BatchNorm2d(16),                   # Normalization \n                        nn.ReLU(True),                       # Activation\n                        nn.MaxPool2d((2,2)),                 # Pooling\n    \n                        # 2nd convolutional network Layers\n                        nn.Conv2d(16,32,(2,2),(1,1),'same'),  # Convolution\n                        nn.BatchNorm2d(32),                  # Normalization \n                        nn.ReLU(True),                       # Activation\n                        nn.MaxPool2d((2,2)),                 # Pooling\n    \n                        # 3rd convolutional network Layers\n                        nn.Conv2d(32,64,(2,2),(1,1),'same'), # Convolution\n                        nn.BatchNorm2d(64),                  # Normalization \n                        nn.ReLU(True),                       # Activation\n                        nn.MaxPool2d((2,2)),                 # Pooling\n\n                        # Flatten Data\n                        nn.Flatten(),                        # Flatten\n    \n                        # feed forward Layers\n                        nn.Linear(1024,256),                  # Linear \n                        nn.ReLU(True),                       # Activation\n                        nn.Linear(256,43)                    # Linear \n                    )\n\n# Send model to Cuda Memory\nmodel = model.to(torch.device('cuda'),non_blocking=True)\n# For Model Summary\nts.summary(model,(3,32,32))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:07:49.866679Z","iopub.execute_input":"2022-06-01T16:07:49.867255Z","iopub.status.idle":"2022-06-01T16:07:59.000053Z","shell.execute_reply.started":"2022-06-01T16:07:49.867219Z","shell.execute_reply":"2022-06-01T16:07:58.998297Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, data, target):\n    # sending data and target to cuda memory\n    data = data.to(torch.device('cuda'),non_blocking=True)\n    target = target.to(torch.device('cuda'),non_blocking=True)\n    length = len(target)\n    yhat = model(data) # predict on data\n    ypred = yhat.argmax(axis=1) # claculate the prediction labels from yhat\n    loss = float(nn.functional.cross_entropy(yhat, target)) # calculate the loss\n    acc = float((ypred == target).sum() / length) # Calculate accuracy\n    print('Loss :',round(loss,4),'- Accuracy :',round(acc,4)) # Print loss and Accuracy\n    del data,target,yhat,ypred # delete the used variables\n    torch.cuda.empty_cache() # Free the Cuda memory","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:07:59.001392Z","iopub.execute_input":"2022-06-01T16:07:59.001891Z","iopub.status.idle":"2022-06-01T16:07:59.009231Z","shell.execute_reply.started":"2022-06-01T16:07:59.001851Z","shell.execute_reply":"2022-06-01T16:07:59.008490Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print('\\nInitial Loss and Accuracy on Test Dataset :')\nevaluate(model,xtest.float(),ytest)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:07:59.010928Z","iopub.execute_input":"2022-06-01T16:07:59.011614Z","iopub.status.idle":"2022-06-01T16:08:00.134341Z","shell.execute_reply.started":"2022-06-01T16:07:59.011574Z","shell.execute_reply":"2022-06-01T16:08:00.133489Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def train_model(model=model,optimizer=torch.optim.Adam,epochs=5,batch_size=200,steps_per_epochs=200,l2_reg=0,max_lr=0.01,grad_clip=0.5):\n    \n    hist = [[],[],[],[]] # hist will stores train and test data losses and accuracy of every epochs\n    \n    train_ds = [(x,y) for x,y in zip(xtrain,ytrain)] # Prepare training dataset for Data Loader\n    training_dl = torch.utils.data.DataLoader(train_ds,batch_size=batch_size) # Data Loader used to train model \n    train_dl = torch.utils.data.DataLoader(train_ds,batch_size=batch_size * steps_per_epochs) \n                                    # Data Loader for epoch end evaluation on train data\n    del train_ds \n    gc.collect() # Delete the used variable and free up memory\n    \n    # Initialized the Optimizer to update weights and bias of model parameters\n    optimizer = optimizer(model.parameters(),weight_decay=l2_reg)\n    \n    # Initialized the Schedular to update learning rate as per one cycle poicy  \n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr,epochs=epochs, steps_per_epoch=int(steps_per_epochs * 1.01))\n        \n    # Training Started\n    for i in range(epochs):\n                 \n        print('\\nEpoch' , i+1 , ': [',end=\"\")\n        \n        # Load Batches of training data loader\n        for j,(xb,yb) in enumerate(training_dl):\n            \n            # move the training batch data to cuda memory for faster processing\n            xb = xb.to(torch.device('cuda'),non_blocking=True)\n            yb = yb.to(torch.device('cuda'),non_blocking=True)\n            \n            # Calculate Losses and gradients\n            yhat = model(xb.float())\n            loss = nn.functional.cross_entropy(yhat, yb)\n            loss.backward()\n            \n            # Clip the outlier like gradients\n            nn.utils.clip_grad_value_(model.parameters(),grad_clip)\n            \n            # Update Weights and bias\n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # Update Learning Rate\n            sched.step()\n            \n            del xb,yb,yhat\n            torch.cuda.empty_cache()\n            # delete the used data and free up space\n            \n            # print the training epochs progress\n            if j % int(steps_per_epochs / 20) == 0:\n                print('.',end='')\n                \n            # break the loop when all steps of an epoch completed. \n            if steps_per_epochs == j :\n                break\n                             \n           \n        # Epochs end evaluation \n        \n        device = torch.device('cuda') # initialized cuda to device\n        \n        # load training data batches from train data loader\n        for xtrainb,ytrainb in train_dl:\n            break\n        \n        # move train data to cuda\n        xtrain_cuda = xtrainb.to(device,non_blocking=True)\n        ytrain_cuda = ytrainb.to(device,non_blocking=True)\n        del xtrainb, ytrainb\n        gc.collect()\n        # delete used variables and free up space\n        \n        # Calculate train loss and accuracy\n        yhat = model(xtrain_cuda.float())\n        ypred = yhat.argmax(axis=1)\n        train_loss = float(nn.functional.cross_entropy(yhat, ytrain_cuda))\n        train_acc = float((ypred == ytrain_cuda).sum() / len(ytrain_cuda))\n        \n        del xtrain_cuda, ytrain_cuda, yhat, ypred\n        torch.cuda.empty_cache()\n        # delete used variables and free up space\n        \n        # move test data to cuda\n        xtest_cuda = xtest.to(device,non_blocking=True)\n        ytest_cuda = ytest.to(device,non_blocking=True)\n        \n        # Calculate test loss and accuracy\n        yhat = model(xtest_cuda.float())\n        ypred = yhat.argmax(axis=1)\n        val_loss = float(nn.functional.cross_entropy(yhat, ytest_cuda))\n        val_acc = float((ypred == ytest_cuda).sum() / len(ytest_cuda))\n        \n        del xtest_cuda, ytest_cuda, yhat, ypred\n        torch.cuda.empty_cache()\n        # delete used variables and free up space\n        \n        # print the captured train and test loss and accuracy at the end of every epochs\n        print('] - Train Loss :',round(train_loss,4),'- Train Accuracy :',round(train_acc,4),\n              '- Val Loss :',round(val_loss,4), '- Val Accuracy :',round(val_acc,4))\n        \n        # store that data into the previously blank initialized hist list \n        hist[0].append(train_loss)\n        hist[1].append(val_loss)\n        hist[2].append(train_acc)\n        hist[3].append(val_acc)\n        \n    # Initialized all the evaluation history of all epochs to a dict\n    history = {'Train Loss':hist[0],'Val Loss':hist[1],'Train Accuracy':hist[2], 'Val Accuracy':hist[3]}\n    \n    # return the history as pandas dataframe\n    return pd.DataFrame(history)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:08:00.136025Z","iopub.execute_input":"2022-06-01T16:08:00.136564Z","iopub.status.idle":"2022-06-01T16:08:00.157197Z","shell.execute_reply.started":"2022-06-01T16:08:00.136526Z","shell.execute_reply":"2022-06-01T16:08:00.156097Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:08:00.159908Z","iopub.execute_input":"2022-06-01T16:08:00.160591Z","iopub.status.idle":"2022-06-01T16:08:00.173049Z","shell.execute_reply.started":"2022-06-01T16:08:00.160558Z","shell.execute_reply":"2022-06-01T16:08:00.172119Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"%%time\nhistory = train_model(model,optimizer=torch.optim.Adam,epochs=15,steps_per_epochs=200,l2_reg=0,max_lr=0.015,grad_clip=0.5)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:08:00.174325Z","iopub.execute_input":"2022-06-01T16:08:00.174879Z","iopub.status.idle":"2022-06-01T16:09:24.508160Z","shell.execute_reply.started":"2022-06-01T16:08:00.174839Z","shell.execute_reply":"2022-06-01T16:09:24.506139Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"history","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:09:24.512810Z","iopub.execute_input":"2022-06-01T16:09:24.515024Z","iopub.status.idle":"2022-06-01T16:09:24.536381Z","shell.execute_reply.started":"2022-06-01T16:09:24.514982Z","shell.execute_reply":"2022-06-01T16:09:24.535270Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# used plotly for interactive plotting\nfig = px.line(history.iloc[:,:2],title='Loss Per Epochs',labels={'value':'Loss','index':'Epochs'})\nfig.update_layout(title={'font_family':'Georgia','font_size':23,'x':0.5}).show()\nfig = px.line(history.iloc[:,2:],title='Accuracy Per Epochs',labels={'value':'Accuracy','index':'Epochs'})\nfig.update_layout(title={'font_family':'Georgia','font_size':23,'x':0.5}).show() ","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:09:24.540584Z","iopub.execute_input":"2022-06-01T16:09:24.541251Z","iopub.status.idle":"2022-06-01T16:09:25.313338Z","shell.execute_reply.started":"2022-06-01T16:09:24.541212Z","shell.execute_reply":"2022-06-01T16:09:25.312573Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# move to cuda \nxtest =  xtest.to(torch.device('cuda'),non_blocking=True)\n# generate predictions\nypred = model(xtest.float()).argmax(axis=1)\n# again move back xtest , ypred to cpu\nxtest = xtest.to(torch.device('cpu'),non_blocking=True)\nypred = ypred.to(torch.device('cpu'),non_blocking=True)\n# calculate the classification metrices and print result \nprint(classification_report(ytest,ypred))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:09:45.877178Z","iopub.execute_input":"2022-06-01T16:09:45.877721Z","iopub.status.idle":"2022-06-01T16:09:46.508818Z","shell.execute_reply.started":"2022-06-01T16:09:45.877687Z","shell.execute_reply":"2022-06-01T16:09:46.507945Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def prediction(img):\n    if type(img) == str:\n        # PIL load the image as PIL object and ToTensor() convert this to a Tensor\n        img = tv.transforms.ToTensor()(PIL.Image.open(img))\n    # resize image to 32X32 as model supports this\n    img = cv2.resize(img.permute(1,2,0).numpy(),(32,32))\n    img = torch.from_numpy(img).permute(2,0,1)\n    # unsqueezed img as inside a tensor and move to cuda\n    img_tensor = img.unsqueeze(0).to(torch.device('cuda'))\n    # Predict the label\n    pred = int(model(img_tensor).argmax(axis=1)[0])\n    # Find the traffic sign name for label from labels_df \n    # that initialize at the begining of the notebook\n    pred_str = labels_df[labels_df['ClassId'] == pred]['Name'][pred]\n    # Show the image using matplotlib\n    plt.figure(figsize=(5,5))\n    plt.imshow(cv2.resize(img.permute(1,2,0).numpy(),(1000,1000)))\n    plt.axis('off')\n    # Print traffic sign that recognized\n    print('\\nRecognized Traffic Sign :',pred_str,'\\n')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:09:50.577365Z","iopub.execute_input":"2022-06-01T16:09:50.578081Z","iopub.status.idle":"2022-06-01T16:09:50.586454Z","shell.execute_reply.started":"2022-06-01T16:09:50.578045Z","shell.execute_reply":"2022-06-01T16:09:50.585257Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"prediction('../input/traffic-signs-classification/myData/16/00001_00006.jpg')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T16:10:50.077599Z","iopub.execute_input":"2022-06-01T16:10:50.077993Z","iopub.status.idle":"2022-06-01T16:10:50.349192Z","shell.execute_reply.started":"2022-06-01T16:10:50.077963Z","shell.execute_reply":"2022-06-01T16:10:50.347204Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}